{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese_Network_CNN_Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzLW5_XkfJQA",
        "colab_type": "code",
        "outputId": "e527ac26-bc59-4aeb-c533-bb341105557b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af1aac06-f580-464b-a901-d29be529de44\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-af1aac06-f580-464b-a901-d29be529de44\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"tanyachutani\",\"key\":\"c55ce1a2caba7c782209c089bba480df\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDtiYECnj8zD",
        "colab_type": "code",
        "outputId": "ee917f26-c348-412a-8c58-004ff8760e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c 'quora-question-pairs'\n",
        "!unzip '/content/train.csv.zip'  \n",
        "!unzip '/content/test.csv.zip'  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 92% 105M/114M [00:02<00:00, 48.8MB/s] \n",
            "100% 114M/114M [00:02<00:00, 56.4MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 43% 9.00M/21.2M [00:00<00:00, 19.1MB/s]\n",
            "100% 21.2M/21.2M [00:00<00:00, 39.2MB/s]\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "100% 4.95M/4.95M [00:00<00:00, 39.6MB/s]\n",
            "\n",
            "Archive:  /content/train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  /content/test.csv.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyX6dE3UxGey",
        "colab_type": "code",
        "outputId": "4bf8c38d-d180-4921-9fe2-8fea9f87dfb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget -P /content/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-19 12:09:29--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.18.211\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.18.211|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/content/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  35.1MB/s    in 45s     \n",
            "\n",
            "2020-05-19 12:10:15 (34.6 MB/s) - ‘/content/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKvCQNnWlkRg",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNGO5ZJk1f21",
        "colab_type": "code",
        "outputId": "d2ad9430-51ac-4477-a3fd-f5a116710350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re, nltk, gensim\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU,Dense,Input,\\\n",
        "BatchNormalization,Bidirectional,concatenate,Dropout,Conv1D,\\\n",
        "MaxPooling1D,Flatten,add,Lambda\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma8V0_0glq1I",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMAGuQr9B54c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(dataset):\n",
        "  train=pd.read_csv(dataset)\n",
        "  train.dropna(axis=0, inplace=True)\n",
        "  return train\n",
        "\n",
        "data=load_data('train.csv')\n",
        "data=data[:10000]\n",
        "\n",
        "#Creating two list one for left and another for the right question\n",
        "def list_data(train):\n",
        "  q1 = pd.Series(train.question1.tolist()).astype(str)\n",
        "  q2 = pd.Series(train.question2.tolist()).astype(str)\n",
        "  return q1,q2\n",
        "\n",
        "q1,q2=list_data(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_KDlzoHRCC9",
        "colab_type": "text"
      },
      "source": [
        "## Counts for positive and negative examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0rvDcCLXZ7D",
        "colab_type": "code",
        "outputId": "1256129e-36c5-4733-914f-9d8ec1a134cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Checking for the output counts (Check for data imbalance)\n",
        "data['is_duplicate'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6289\n",
              "1    3711\n",
              "Name: is_duplicate, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F26PW3G3mGGx",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the text data\n",
        "\n",
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Mjs029358_",
        "colab_type": "code",
        "outputId": "3a27460f-6aaa-4368-9866-48a7d834eedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def text_clean(corpus):\n",
        "    cleaned_corpus = pd.Series()\n",
        "    for row in corpus:\n",
        "        qs_list = []\n",
        "        for word in row.split():\n",
        "            word = word.lower()\n",
        "            word = re.sub(r\"[^a-zA-Z0-9^.']\",\" \",word)\n",
        "            p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
        "            qs_list.append(p1)\n",
        "        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs_list)))\n",
        "    return cleaned_corpus\n",
        "\n",
        "all_corpus = q1.append(q2)\n",
        "all_corpus = text_clean(all_corpus)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fW0pNaR5UhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The data is in format like all q1 are the in the starting \n",
        "#rows of all_corpus\n",
        "#then once q1 gets finished, q2 starts. So again \n",
        "#separating q1 and q2 and merging them into a data frame.\n",
        "def clean_data(all_corpus,q1,q2,train):\n",
        "  q1 = all_corpus[0:q1.shape[0]]\n",
        "  q2 = all_corpus[q2.shape[0]::]\n",
        "  data_out = pd.DataFrame({'q1': q1, 'q2': q2})\n",
        "  data_out.index=list(range(0,len(data_out)))\n",
        "  data_out['output']=train['is_duplicate']\n",
        "  return data_out\n",
        "data_new=clean_data(all_corpus,q1,q2,data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkcGCEBTmynw",
        "colab_type": "text"
      },
      "source": [
        "### Creating word to index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP20saPEaKqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating word to index using keras tokenizer\n",
        "def word_to_index(all_corpus):\n",
        "  lines = []\n",
        "  for key in all_corpus:\n",
        "    lines.append(key)\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return(tokenizer.word_index)\n",
        "word2index=word_to_index(all_corpus)\n",
        "index2word = dict((v,k) for k,v in word2index.items())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT6dn69Lm23C",
        "colab_type": "text"
      },
      "source": [
        "### Implementing word2vec embedding on text data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L05AHdP7rJUJ",
        "colab_type": "code",
        "outputId": "36961864-0028-498f-eeee-ff8eb427c10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Loading pre-trained word vectors\n",
        "def load_embedding(EMBEDDING_FILE,embedding_dim):\n",
        "  word2vec_model = gensim.models.KeyedVectors.\\\n",
        "  load_word2vec_format(EMBEDDING_FILE, binary = True)\n",
        "  w2v = dict(zip(word2vec_model.wv.index2word,\\\n",
        "                 word2vec_model.wv.syn0))\n",
        "  \n",
        "# This will be the embedding matrix\n",
        "  embeddings = 1 * np.random.randn(len(word2index) \\\n",
        "                                   + 1, embedding_dim)  \n",
        "  embeddings[0] = 0  # So that the padding will be ignored\n",
        "\n",
        "\n",
        "# Build the embedding matrix\n",
        "  for word, index in word2index.items():\n",
        "      if word in word2vec_model.vocab:\n",
        "          embeddings[index] = word2vec_model.word_vec(word)\n",
        "  return embeddings\n",
        "\n",
        "embedding_dim=300\n",
        "EMBEDDING_FILE = '/content/GoogleNews-vectors-negative300.bin.gz'\n",
        "\n",
        "embeddings=load_embedding(EMBEDDING_FILE,embedding_dim)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRpbeZ1bm_qg",
        "colab_type": "text"
      },
      "source": [
        "### Max length \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih2JQn9OcfYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(all_corpus):\n",
        "  lines=[]\n",
        "  max_len=-1\n",
        "  for key in all_corpus:\n",
        "    for d in key:\n",
        "      if len(d.split())>max_len:\n",
        "        max_len=len(d.split())\n",
        "  return max_len\n",
        "\n",
        "max_len=max_length(all_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOIHKX-enFyT",
        "colab_type": "text"
      },
      "source": [
        "## Creating training data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGnLw9OjwBs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#If len is not equal to max_len then doing post padding\n",
        "max_len=30\n",
        "def create_train_data(dataset,max_length,column):\n",
        "  X1=list()\n",
        "  for idx in range(len(dataset)):\n",
        "    for words in (data_new.iloc[idx][[column]].values):\n",
        "      numeric_seq = [word2index[word] for word \\\n",
        "                     in words.split() if word in word2index]\n",
        "      in_seq=numeric_seq\n",
        "      in_seq=pad_sequences([in_seq],maxlen=max_length,\\\n",
        "                           padding='post')[0]\n",
        "      X1.append(in_seq)\n",
        "  return X1\n",
        "\n",
        "q1=np.array(create_train_data(data_new,max_len,'q1'))\n",
        "q2=np.array(create_train_data(data_new,max_len,'q2'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaxJW46insqU",
        "colab_type": "text"
      },
      "source": [
        "## Train Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StilL-luN4t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_test(q1,q2,data):\n",
        "  X = np.stack((q1, q2), axis=1)\n",
        "  X_train, X_test, y_train, y_test = X[:-10], \\\n",
        "  X[-10:],list(data['is_duplicate'])[:-10],list(data['is_duplicate'])[-10:]\n",
        "  train_q1 = X_train[:,0]\n",
        "  train_q2 = X_train[:,1]\n",
        "  test_q1 = X_test[:,0]\n",
        "  test_q2 = X_test[:,1]\n",
        "  return train_q1,train_q2,test_q1,test_q2,\\\n",
        "  y_train,y_test,X_train,X_test\n",
        "train_q1,train_q2,test_q1,test_q2,y_train,\\\n",
        "y_test,X_train,X_test=split_train_test(q1,q2,data)\n",
        "y_train=np.array(y_train)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev5GCpGFny3B",
        "colab_type": "text"
      },
      "source": [
        "## Euclidean distance and Cosine distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl5sOVg_Z_cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cosine distance\n",
        "def cosine_distance(output):\n",
        "  x, y= output[0],output[1]\n",
        "  x = K.l2_normalize(x, axis=-1)\n",
        "  y = K.l2_normalize(y, axis=-1)\n",
        "  return -K.mean(x * y, axis=-1, keepdims=True)\n",
        "\n",
        "def euclidean_distance(output):\n",
        "    x, y = output[0],output[1]\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktTtkm28n3HA",
        "colab_type": "text"
      },
      "source": [
        "## Contrastive Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8hbLMTTqe5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return (y_true * K.square(y_pred)\\\n",
        "            + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return K.mean(tf.cast(tf.equal(y_true, tf.cast(y_pred < 0.5, dtype=tf.float32)), dtype=tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owXPgFP8oCko",
        "colab_type": "text"
      },
      "source": [
        "## First Model Stacked Birectional GRU with cosine distance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IZBXeEvDFv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gru_model(input_shape,embeddings,embedding_dim):\n",
        "  model_input = Input(shape=(input_shape,))\n",
        "  layer = Embedding(len(embeddings), \n",
        "                 embedding_dim, \n",
        "                 weights=[embeddings], \n",
        "                 input_length=max_len, \n",
        "                 trainable=True)(model_input)\n",
        "  layer = Bidirectional(GRU(200, return_sequences=True))(layer)\n",
        "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
        "  layer = Bidirectional(GRU(200,return_sequences=True,dropout=0.2,\n",
        "                            recurrent_dropout=0.2))(layer)\n",
        "  layer = tf.keras.layers.BatchNormalization()(layer)\n",
        "  output = Bidirectional(GRU(200,return_sequences=False,dropout=0.2,\n",
        "                            recurrent_dropout=0.2))(layer)\n",
        "  model = Model(inputs=model_input, outputs=output)\n",
        "  return model\n",
        "\n",
        "model = gru_model(max_len,embeddings,embedding_dim)\n",
        "\n",
        "input_q1 = Input(shape=(max_len,))\n",
        "input_q2 = Input(shape=(max_len,))\n",
        "\n",
        "left_out = model(input_q1)\n",
        "right_out = model(input_q2)\n",
        "\n",
        "output = Lambda(euclidean_distance, name='euclidean_distance')\\\n",
        "([left_out, right_out])\n",
        "\n",
        "gru_model = Model(inputs=[input_q1,input_q2], outputs=output)\n",
        "gru_model.summary()\n",
        "\n",
        "gru_model.compile(loss=contrastive_loss, optimizer='adam',\\\n",
        "              metrics=[accuracy])\n",
        "callback = [ModelCheckpoint('question_pairs_weights_gru.h5',\\\n",
        "                            monitor='accuracy', save_best_only=True,mode='max'),\n",
        "            TensorBoard(log_dir='/content/logs', write_graph=True)\n",
        "            ]\n",
        "\n",
        "history = gru_model.fit([train_q1,train_q2],\n",
        "                    y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=10,\n",
        "                    callbacks=callback,\n",
        "                    validation_split=0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G71orVS4ofP9",
        "colab_type": "text"
      },
      "source": [
        "## Result\n",
        "\n",
        "#### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHYv9sAuHKUf",
        "colab_type": "code",
        "outputId": "335aa966-a888-421f-af3b-7e578ce243f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "y_pred=gru_model.predict([test_q1,test_q2])\n",
        "data_new_test=data_new[-10:]\n",
        "data_new_test['Y_prediction']=[i for i in y_pred]\n",
        "data_new_test"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1</th>\n",
              "      <th>q2</th>\n",
              "      <th>output</th>\n",
              "      <th>Y_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9990</th>\n",
              "      <td>why does 500 and 1000 rs notes banned by goi a...</td>\n",
              "      <td>what do you think of the decision by the india...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.38043028]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>how do i stop a css layout from distorting whe...</td>\n",
              "      <td>what are the different types of css layouts</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.77639353]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>is a world war going to happen</td>\n",
              "      <td>can world war 3 ever take place</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.3749664]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>early elizabethan dramalists</td>\n",
              "      <td>what do muslims think of pig slaughter</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.58103967]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>what was it like flying first class in the 1990s</td>\n",
              "      <td>what is it like flying first class</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.26551232]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>how would you order these four cities  bangalo...</td>\n",
              "      <td>what is the cost of living in europe and the u...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.2808392]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>stphen william hawking</td>\n",
              "      <td>what are the differences between sm  yg and jy...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.341012]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>mathematical puzzles  what is                3...</td>\n",
              "      <td>what are the steps to solve this equation   ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.3909037]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>is ims noida good for bca</td>\n",
              "      <td>how good is ims noida for studying bca</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.3366593]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>what are the most respected and informative te...</td>\n",
              "      <td>what are caltech s required and recommended te...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.2772219]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     q1  ...  Y_prediction\n",
              "9990  why does 500 and 1000 rs notes banned by goi a...  ...  [0.38043028]\n",
              "9991  how do i stop a css layout from distorting whe...  ...  [0.77639353]\n",
              "9992                    is a world war going to happen   ...   [0.3749664]\n",
              "9993                      early elizabethan dramalists   ...  [0.58103967]\n",
              "9994  what was it like flying first class in the 1990s   ...  [0.26551232]\n",
              "9995  how would you order these four cities  bangalo...  ...   [1.2808392]\n",
              "9996                            stphen william hawking   ...    [1.341012]\n",
              "9997  mathematical puzzles  what is                3...  ...   [1.3909037]\n",
              "9998                         is ims noida good for bca   ...   [0.3366593]\n",
              "9999  what are the most respected and informative te...  ...   [1.2772219]\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp_Rjdqsohxc",
        "colab_type": "text"
      },
      "source": [
        "## Second model CNN Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_aS-_ky4o1K",
        "colab_type": "code",
        "outputId": "f11da37f-4e28-4db8-e142-5ba833c907c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def cnn_model(input_shape,embeddings,embedding_dim):\n",
        "  model_input = Input(shape=(input_shape,))\n",
        "  layer = Embedding(len(embeddings), \n",
        "                 embedding_dim, \n",
        "                 weights=[embeddings], \n",
        "                 input_length=max_len, \n",
        "                 trainable=False)(model_input)\n",
        "  layer = Conv1D(filters=64,kernel_size=3,activation='relu')(layer)\n",
        "  layer = MaxPooling1D(pool_size=2)(layer)\n",
        "  layer = Dropout(0.2)(layer)\n",
        "  layer = Conv1D(filters=64,kernel_size=2,activation='relu')(layer)\n",
        "  layer = MaxPooling1D(pool_size=2)(layer)\n",
        "  layer = Dropout(0.2)(layer)\n",
        "  layer = Conv1D(filters=64,kernel_size=2,activation='relu')(layer)\n",
        "  layer = MaxPooling1D(pool_size=2)(layer)\n",
        "  output = Flatten()(layer)\n",
        "  \n",
        "  model = Model(inputs=model_input, outputs=output)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "cnn_model = cnn_model(max_len,embeddings,embedding_dim)\n",
        "\n",
        "input_q1 = Input(shape=(max_len,))\n",
        "input_q2 = Input(shape=(max_len,))\n",
        "\n",
        "left_out = cnn_model(input_q1)\n",
        "right_out = cnn_model(input_q2)\n",
        "\n",
        "output = Lambda(euclidean_distance, name='euclidean_distance')\\\n",
        "([left_out, right_out])\n",
        "\n",
        "cnn_model = Model(inputs=[input_q1,input_q2], outputs=output)\n",
        "cnn_model.summary()\n",
        "\n",
        "cnn_model.compile(loss=contrastive_loss, optimizer='adam',\\\n",
        "              metrics=[accuracy])\n",
        "\n",
        "callback = [ModelCheckpoint('question_pairs_weights_cnn.h5',\\\n",
        "                            monitor='accuracy', save_best_only=True,mode='max')]\n",
        "\n",
        "history = cnn_model.fit([train_q1,train_q2],\n",
        "                    y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=10,\n",
        "                    callbacks=callback)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 30, 300)           4505400   \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 28, 64)            57664     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 14, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 14, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 13, 64)            8256      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 6, 64)             0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 64)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 5, 64)             8256      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 2, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 128)               0         \n",
            "=================================================================\n",
            "Total params: 4,579,576\n",
            "Trainable params: 74,176\n",
            "Non-trainable params: 4,505,400\n",
            "_________________________________________________________________\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_4 (Model)                 (None, 128)          4579576     input_8[0][0]                    \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "euclidean_distance (Lambda)     (None, 1)            0           model_4[1][0]                    \n",
            "                                                                 model_4[2][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,579,576\n",
            "Trainable params: 74,176\n",
            "Non-trainable params: 4,505,400\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "999/999 [==============================] - 11s 11ms/step - loss: 0.2632 - accuracy: 0.6072\n",
            "Epoch 2/10\n",
            "999/999 [==============================] - 11s 11ms/step - loss: 0.2218 - accuracy: 0.6448\n",
            "Epoch 3/10\n",
            "999/999 [==============================] - 11s 11ms/step - loss: 0.2101 - accuracy: 0.6665\n",
            "Epoch 4/10\n",
            "999/999 [==============================] - 13s 13ms/step - loss: 0.2043 - accuracy: 0.6771\n",
            "Epoch 5/10\n",
            "999/999 [==============================] - 12s 12ms/step - loss: 0.1974 - accuracy: 0.6940\n",
            "Epoch 6/10\n",
            "999/999 [==============================] - 10s 10ms/step - loss: 0.1900 - accuracy: 0.7095\n",
            "Epoch 7/10\n",
            "999/999 [==============================] - 10s 10ms/step - loss: 0.1841 - accuracy: 0.7231\n",
            "Epoch 8/10\n",
            "999/999 [==============================] - 9s 9ms/step - loss: 0.1749 - accuracy: 0.7392\n",
            "Epoch 9/10\n",
            "999/999 [==============================] - 10s 10ms/step - loss: 0.1686 - accuracy: 0.7518\n",
            "Epoch 10/10\n",
            "999/999 [==============================] - 10s 10ms/step - loss: 0.1630 - accuracy: 0.7629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjEm1up72um0",
        "colab_type": "text"
      },
      "source": [
        "### Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ljZmnTgkWz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "ddea4f23-b3c8-4960-c2f3-304a53b48c4e"
      },
      "source": [
        "y_pred=cnn_model.predict([test_q1,test_q2])\n",
        "data_new_test=data_new[-10:]\n",
        "data_new_test['Y_prediction']=[i for i in y_pred]\n",
        "data_new_test"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1</th>\n",
              "      <th>q2</th>\n",
              "      <th>output</th>\n",
              "      <th>Y_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9990</th>\n",
              "      <td>why does 500 and 1000 rs notes banned by goi a...</td>\n",
              "      <td>what do you think of the decision by the india...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>how do i stop a css layout from distorting whe...</td>\n",
              "      <td>what are the different types of css layouts</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.39628065]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9992</th>\n",
              "      <td>is a world war going to happen</td>\n",
              "      <td>can world war 3 ever take place</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.058691166]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9993</th>\n",
              "      <td>early elizabethan dramalists</td>\n",
              "      <td>what do muslims think of pig slaughter</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.33805332]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9994</th>\n",
              "      <td>what was it like flying first class in the 1990s</td>\n",
              "      <td>what is it like flying first class</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.77967125]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>how would you order these four cities  bangalo...</td>\n",
              "      <td>what is the cost of living in europe and the u...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.20272695]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>stphen william hawking</td>\n",
              "      <td>what are the differences between sm  yg and jy...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.8747106]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>mathematical puzzles  what is                3...</td>\n",
              "      <td>what are the steps to solve this equation   ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.4450378]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>is ims noida good for bca</td>\n",
              "      <td>how good is ims noida for studying bca</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.29204148]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>what are the most respected and informative te...</td>\n",
              "      <td>what are caltech s required and recommended te...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0701656]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     q1  ...   Y_prediction\n",
              "9990  why does 500 and 1000 rs notes banned by goi a...  ...          [0.0]\n",
              "9991  how do i stop a css layout from distorting whe...  ...   [0.39628065]\n",
              "9992                    is a world war going to happen   ...  [0.058691166]\n",
              "9993                      early elizabethan dramalists   ...   [0.33805332]\n",
              "9994  what was it like flying first class in the 1990s   ...   [0.77967125]\n",
              "9995  how would you order these four cities  bangalo...  ...   [0.20272695]\n",
              "9996                            stphen william hawking   ...    [1.8747106]\n",
              "9997  mathematical puzzles  what is                3...  ...    [1.4450378]\n",
              "9998                         is ims noida good for bca   ...   [0.29204148]\n",
              "9999  what are the most respected and informative te...  ...    [1.0701656]\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}